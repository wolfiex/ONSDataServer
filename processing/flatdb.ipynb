{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6debbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE310 Output_Areas 2001\n",
      "TYPE299 Output_Areas 2011\n",
      "TYPE304 Lower_Layer_Super_Output_Areas 2001\n",
      "TYPE298 Lower_Layer_Super_Output_Areas 2011\n",
      "TYPE305 Middle_Layer_Super_Output_Areas 2001\n",
      "TYPE297 Middle_Layer_Super_Output_Areas 2011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time,os,sys\n",
    "from p_tqdm import p_map\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sqlite3\n",
    "sqlite3.register_adapter(np.int64, lambda val: int(val))\n",
    "sqlite3.register_adapter(np.int32, lambda val: int(val))\n",
    "\n",
    "from const import DATASETS,SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef0c02",
   "metadata": {},
   "source": [
    "### Merge all centroids for relevant Layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7207d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Output_Areas'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_centroids(kind):\n",
    "areatype = 'Output_Areas'    \n",
    "if 'Areas' in sys.argv[1]:\n",
    "    areatype = sys.argv[1]\n",
    "\n",
    "__outdir__='flatdb/'+areatype\n",
    "try:os.mkdir(__outdir__)\n",
    "except:pass\n",
    "\n",
    "areatype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e2c473b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PARENTS\n",
       "E06000001    [E00060255, E00060256, E00060257, E00060258, E...\n",
       "E06000002    [E00060556, E00060557, E00060558, E00060559, E...\n",
       "E06000003    [E00060999, E00061000, E00061001, E00061002, E...\n",
       "E06000004    [E00061461, E00061462, E00061463, E00061464, E...\n",
       "E06000005    [E00062043, E00062044, E00062045, E00062046, E...\n",
       "                                   ...                        \n",
       "W06000020    [W00007742, W00007743, W00007744, W00007745, W...\n",
       "W06000021    [W00008044, W00008045, W00008046, W00008047, W...\n",
       "W06000022    [W00008328, W00008329, W00008330, W00008331, W...\n",
       "W06000023    [W00002268, W00002269, W00002270, W00002271, W...\n",
       "W06000024    [W00006756, W00006757, W00006758, W00006759, W...\n",
       "Length: 173, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = pd.read_csv(__outdir__+'/mapping.csv')\n",
    "\n",
    "geomap = dict(zip(mapping.AREAID,mapping.AREACD))\n",
    "\n",
    "# mapping.groupby('PARENTS AREAID AREACD'.split()).count().index\n",
    "groups = mapping.groupby('PARENTS').apply(lambda x: list(x.AREAID))\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191aa06",
   "metadata": {},
   "source": [
    "##  A function to get the individual dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e49b5fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(url, src):\n",
    "    '''Read each individaul query and return a dataframe'''\n",
    "    # print(url)\n",
    "    dummydf = pd.read_csv(url)\n",
    "    dummydf.columns = 'GEOGRAPHY_CODE YEAR CELL OBS_VALUE'.split()\n",
    "\n",
    "    if 'cellmaps' in src:\n",
    "        cells = '0,'+','.join(src['cellnames'])\n",
    "        cells = ','.join(src['cellnames'])\n",
    "        for v, k in src['cellmaps'].items(): \n",
    "            for c in k: \n",
    "                cells = cells.replace(c,v)\n",
    "        src['cellnames'] = ('Totals,'+cells).split(',')\n",
    "\n",
    "    mapping = dict(zip(eval(src['cells']), src['cellnames']))\n",
    "    dummydf['CELL'] = dummydf['CELL'].apply(lambda x: mapping[x])   # (rename,mapping = mapping)\n",
    "    return dummydf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831dee99",
   "metadata": {},
   "source": [
    "## Process each Year and concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35192fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(dataset):\n",
    "    '''Fetch the data from the source'''\n",
    "    global SETTINGS\n",
    "    time.sleep(np.random.rand()*10.)\n",
    "    sources = dataset['sources']\n",
    "\n",
    "    df = False\n",
    "    \n",
    "    for src in sources:\n",
    "        src = src.copy()\n",
    "        src['cells'] = ','.join(map(str, src['cells']))\n",
    "        src['selection'] = ','.join(map(str, src['selection']))\n",
    "        src['key'] = SETTINGS.conf['apikey']\n",
    "        src['geocode'] = SETTINGS.geocode[areatype][src['year']]\n",
    "        if not hasattr(src, 'query_misc'): src['query_misc'] = ''\n",
    "\n",
    "        url = SETTINGS.conf['apiurl'].format(**src)\n",
    "        if type(df) != bool: df = pd.concat([df, process_df(url, src)]) # df.append(process_df(url,src))\n",
    "        else: df = process_df(url, src)\n",
    "        # print(df.tail(2))\n",
    "\n",
    "    # return df\n",
    "    print('mapping')\n",
    "    # subcategory = mapping\n",
    "    df = df[['GEOGRAPHY_CODE', 'CELL', 'OBS_VALUE','YEAR']]\n",
    "    df = df.sort_values('CELL')\n",
    "    order = df.CELL.drop_duplicates().to_list()\n",
    "\n",
    "\n",
    "    if 'Totals' not in order: \n",
    "        b = df.groupby('GEOGRAPHY_CODE').sum()\n",
    "        b.CELL = 'Totals'\n",
    "        df = pd.concat([df,b.reset_index()],axis=0)  \n",
    "        order=['Totals']+order\n",
    "\n",
    "    mapping = dict(zip(order, range(len(order))))\n",
    "    \n",
    "    # print(order)\n",
    "\n",
    "    # datamong\n",
    "#  drop novalues\n",
    "\n",
    "    df = df[df.GEOGRAPHY_CODE.isin(geomap.keys())]\n",
    "    df['GEOGRAPHY_CODE'] = df['GEOGRAPHY_CODE'].apply(lambda x: geomap[x]).astype(np.uint16)\n",
    "    i = df.groupby(['GEOGRAPHY_CODE', 'CELL']).sum().astype(np.uint32).reset_index()\n",
    "    i.CELL = [mapping[k] for k in i.CELL]\n",
    "    i = i[i.OBS_VALUE > 0] # remove zero values\n",
    "\n",
    "    # return i[['GEOGRAPHY_CODE', 'CELL', 'OBS_VALUE']]]\n",
    "    \n",
    "\n",
    "    return [dataset['code'], order , i[['GEOGRAPHY_CODE', 'CELL', 'OBS_VALUE']]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5db9df21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2001': 'TYPE310', '2011': 'TYPE299'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SETTINGS.geocode[areatype]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aae15d",
   "metadata": {},
   "source": [
    "### Parallel Fetch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d880f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [06:09<36:54, 369.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [07:53<17:47, 213.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [10:01<11:38, 174.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [13:34<09:28, 189.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [15:49<05:40, 170.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [17:59<02:36, 156.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [21:40<00:00, 185.82s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in tqdm(DATASETS):\n",
    "    try:results.append(fetch(i))\n",
    "    except:results.append(fetch(i))\n",
    "\n",
    "\n",
    "# print(results)\n",
    "# a = fetch(DATASETS[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93572a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['population',\n",
       " ['Totals', 'female', 'male'],\n",
       "         GEOGRAPHY_CODE  CELL  OBS_VALUE\n",
       " 0                    0     1        556\n",
       " 1                    0     2        578\n",
       " 2                    1     1        530\n",
       " 3                    1     2        574\n",
       " 4                    2     1        208\n",
       " ...                ...   ...        ...\n",
       " 130963           65533     2        311\n",
       " 130964           65534     1        393\n",
       " 130965           65534     2        358\n",
       " 130966           65535     1        420\n",
       " 130967           65535     2        389\n",
       " \n",
       " [130968 rows x 3 columns]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17bbde4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write cell maps to json\n"
     ]
    }
   ],
   "source": [
    "cellmap  = {}\n",
    "for name,columns,_ in results:\n",
    "    cellmap[name] = dict(zip(range(len(columns)),columns))\n",
    "\n",
    "cellmap[results[0][0]]\n",
    "\n",
    "print('write cell maps to json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5843ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump( results, open( \"results.p\", \"wb\" ) )\n",
    "# pickle.load( open( \"save.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce2c9337",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot index by location index with a non-integer key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h8/t803dxss41g9kj07lkgx95fm0000gn/T/ipykernel_75982/2959148356.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPARENTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index by location index with a non-integer key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot index by location index with a non-integer key"
     ]
    }
   ],
   "source": [
    "for p in mapping.PARENTS:\n",
    "    df =  mapping.iloc[p]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a69a8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h8/t803dxss41g9kj07lkgx95fm0000gn/T/ipykernel_75982/3899260060.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'NAME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# cur = conn.cursor()\n",
    "\n",
    "\n",
    "for name,order,df in results:\n",
    "    print(name)\n",
    "    order = pd.DataFrame(order, columns = ['NAME'])\n",
    "    # order['CELL'] = order.index\n",
    "    # print(order)\n",
    "    df.to_sql(name, con=conn, if_exists='replace',index_label='GEOMETRY_ID')\n",
    "    order.to_sql(name+'_names', con=conn, if_exists='replace',index_label='CELL')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cced94",
   "metadata": {},
   "source": [
    "### Write To DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea234c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7b95659",
   "metadata": {},
   "source": [
    "### SHRINK THE DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "file_size = Path(db_file).stat().st_size\n",
    "\n",
    "print(\"The file size WAS:\", file_size/1048576,\"MB\")\n",
    "\n",
    "conn.execute(\"VACUUM\") ### SHRINK!!!!\n",
    "conn.close()\n",
    "\n",
    "file_size = Path(db_file).stat().st_size\n",
    "\n",
    "print(\"The file size is:\", file_size/1048576,\"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6658934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f3a6e5f",
   "metadata": {},
   "source": [
    "### CENTROIDS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3768002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = results[1]\n",
    "# print(a)\n",
    "# print(a[a.YEAR==2011])\n",
    "# # [geomap[i] for i in a.GEOGRAPHY_CODE]\n",
    "\n",
    "# geomap\n",
    "# e=a[:].GEOGRAPHY_CODE.drop_duplicates()\n",
    "# print(e)\n",
    "# s = 0 \n",
    "# f = 0\n",
    "# miss = []\n",
    "# for i in e.values:\n",
    "\n",
    "#     try:\n",
    "#         (geomap[i])\n",
    "#         s+=1\n",
    "#     except:\n",
    "#         f+=1\n",
    "#         miss.append(i)\n",
    "# print(s,f,len(miss))\n",
    "        \n",
    "# print(miss[:20])\n",
    "# geomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1787e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44f4455e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b6900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb8a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ebffe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a6a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
