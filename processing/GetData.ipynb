{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6debbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from p_tqdm import p_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f02ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import DATASETS,SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ae7207d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    " 'apiurl': 'http://www.nomisweb.co.uk/api/v01/dataset/{dataset}.data.csv?date=latest&geography={geocode}&{cell}={cells}&measures=20100&select={selection}&uid={key}{query_misc}',\n",
    " 'apikey': '0x3cfb19ead752b37bb90da0eb3a0fe78baa9fa055',\n",
    "#  'outfile': './data.h5'\n",
    "}\n",
    "\n",
    "area = {#geocode\n",
    "    'lad':'TYPE464'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for areatype in area:\n",
    "areatype = 'lad'\n",
    "\n",
    "db_file = f'./{areatype}.sqlite'\n",
    "import sqlite3\n",
    "sqlite3.register_adapter(np.int64, lambda val: int(val))\n",
    "sqlite3.register_adapter(np.int32, lambda val: int(val))\n",
    "conn = sqlite3.connect(db_file)\n",
    "# cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f4626",
   "metadata": {},
   "source": [
    "## Generate a area and total tally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "540bd911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.nomisweb.co.uk/api/v01/dataset/NM_1634_1.data.csv?date=latest&geography=TYPE464&cell=1,2&measures=20100&select=geography_code,date_name,cell,obs_value&uid=0x3cfb19ead752b37bb90da0eb3a0fe78baa9fa055\n",
      "http://www.nomisweb.co.uk/api/v01/dataset/NM_144_1.data.csv?date=latest&geography=TYPE464&cell=1,2&measures=20100&select=geography_code,date_name,cell,obs_value&uid=0x3cfb19ead752b37bb90da0eb3a0fe78baa9fa055\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREACD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOGRAPHY_CODE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E06000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E06000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E06000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E06000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>W06000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>W06000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>W06000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>W06000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>W06000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>348 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AREACD\n",
       "GEOGRAPHY_CODE           \n",
       "0               E06000001\n",
       "1               E06000002\n",
       "2               E06000003\n",
       "3               E06000004\n",
       "4               E06000005\n",
       "...                   ...\n",
       "343             W06000020\n",
       "344             W06000021\n",
       "345             W06000022\n",
       "346             W06000023\n",
       "347             W06000024\n",
       "\n",
       "[348 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pop = filter(lambda x:x['code'] == 'population',DATASETS).__next__()\n",
    "sources = pop['sources']\n",
    "df = False\n",
    "\n",
    "for src in sources:\n",
    "\n",
    "    src = src.copy()\n",
    "    src['cells'] = ','.join(map(str,src['cells']))\n",
    "    src['selection'] = ','.join(map(str,src['selection']))\n",
    "    src['key'] = conf['apikey']\n",
    "    if not hasattr(src,'query_misc'):\n",
    "        src['query_misc']=''\n",
    "    url = conf['apiurl'].format(**src)\n",
    "    print(url)\n",
    "    if type(df)!= bool:\n",
    "        df = df.append(pd.read_csv(url),)\n",
    "    else:\n",
    "        df = pd.read_csv(url)\n",
    "        \n",
    "## on the assumption that geography codes for each year are different\n",
    "population = df.groupby('GEOGRAPHY_CODE').first()['OBS_VALUE']\n",
    "\n",
    "p_ref = pd.DataFrame(population.index).reset_index()\n",
    "p_ref.columns = ['GEOGRAPHY_CODE','AREACD']\n",
    "p_ref.set_index('GEOGRAPHY_CODE',inplace=True)\n",
    "\n",
    "\n",
    "p_ref.to_sql('area_'+areatype,conn,if_exists='replace')\n",
    "geomap = dict(zip(p_ref['AREACD'],p_ref.index))\n",
    "\n",
    "p_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191aa06",
   "metadata": {},
   "source": [
    "##  A function to get the individual dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e49b5fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(url, src):\n",
    "    # print(url)\n",
    "    dummydf = pd.read_csv(url)\n",
    "    dummydf.columns = 'GEOGRAPHY_CODE YEAR CELL OBS_VALUE'.split()\n",
    "\n",
    "    if 'cellmaps' in src:\n",
    "        cells = '0,'+','.join(src['cellnames'])\n",
    "        cells = ','.join(src['cellnames'])\n",
    "        for v, k in src['cellmaps'].items():\n",
    "            for c in k:\n",
    "                cells = cells.replace(c,v)\n",
    "\n",
    "        src['cellnames'] = ('Totals,'+cells).split(',')\n",
    "\n",
    "    mapping = dict(zip(eval(src['cells']), src['cellnames']))\n",
    "\n",
    "    dummydf['CELL'] = dummydf['CELL'].apply(lambda x: mapping[x])   # (rename,mapping = mapping)\n",
    "\n",
    "    return dummydf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831dee99",
   "metadata": {},
   "source": [
    "## Process each Year and concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "35192fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(dataset):\n",
    "    sources = dataset['sources']\n",
    "    #     src = sources[0].copy()\n",
    "    #      dont use pointers copy\n",
    "\n",
    "    df = False\n",
    "    for src in sources:\n",
    "        src = src.copy()\n",
    "        src['cells'] = ','.join(map(str, src['cells']))\n",
    "        src['selection'] = ','.join(map(str, src['selection']))\n",
    "        src['key'] = conf['apikey']\n",
    "        if not hasattr(src, 'query_misc'):\n",
    "            src['query_misc'] = ''\n",
    "\n",
    "        url = conf['apiurl'].format(**src)\n",
    "#         print(url)\n",
    "        if type(df) != bool:\n",
    "            df = pd.concat([df, process_df(url, src)])# df.append(process_df(url,src))\n",
    "        else:\n",
    "            df = process_df(url, src)\n",
    "\n",
    "\n",
    "    # subcategory = mapping\n",
    "    # print(df.columns)\n",
    "    df = df[['GEOGRAPHY_CODE', 'CELL', 'OBS_VALUE','YEAR']]\n",
    "    df = df.sort_values('CELL')\n",
    "    order = df.CELL.drop_duplicates().to_list()\n",
    "\n",
    "\n",
    "    if 'Totals' not in order: \n",
    "        b = df.groupby('GEOGRAPHY_CODE').sum()\n",
    "        b.CELL = 'Totals'\n",
    "        df = pd.concat([df,b.reset_index()],axis=0)  \n",
    "        order=['Totals']+order\n",
    "\n",
    "    # else:\n",
    "    #     order.remove('Totals')\n",
    "    # # guarantee that totals is first and referenced as '0'\n",
    "    # order = ['Totals'] + order\n",
    "    mapping = dict(zip(order, range(len(order))))\n",
    "    \n",
    "\n",
    "    # datamong\n",
    "    df['GEOGRAPHY_CODE'] = df['GEOGRAPHY_CODE'].apply(lambda x: geomap[x]).astype(np.uint8)\n",
    "    i = df.groupby(['GEOGRAPHY_CODE', 'CELL']).sum().astype(np.uint32).reset_index()\n",
    "    i.CELL = [mapping[k] for k in i.CELL]\n",
    "    \n",
    "\n",
    "    return [dataset['code'], list(enumerate(order)), i[['GEOGRAPHY_CODE', 'CELL', 'OBS_VALUE']]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aae15d",
   "metadata": {},
   "source": [
    "### Parallel Fetch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "95a69a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:28<00:00,  4.04s/it]\n"
     ]
    }
   ],
   "source": [
    "results = p_map(fetch,DATASETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cced94",
   "metadata": {},
   "source": [
    "### Write To DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "94f85e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population\n",
      "age\n",
      "ethnicity\n",
      "health\n",
      "economic\n",
      "travel\n",
      "tenure\n"
     ]
    }
   ],
   "source": [
    "for name,order,df in results:\n",
    "    print(name)\n",
    "#     df.set_index('GEOGRAPHY_CODE',inplace=True)\n",
    "    df.to_sql(name, con=conn, if_exists='replace')\n",
    "    \n",
    "    order = pd.DataFrame(order,columns = ['CELL','name']).set_index('CELL')\n",
    "    order.to_sql(name+'_names', con=conn, if_exists='replace',index_label='CELL')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b95659",
   "metadata": {},
   "source": [
    "### SRINK THE DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "55e5ac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file size WAS: 0.9453125 MB\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "Cannot operate on a closed database.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h8/t803dxss41g9kj07lkgx95fm0000gn/T/ipykernel_43922/3857830425.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The file size WAS:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1048576\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"MB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"VACUUM\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### SHRINK!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: Cannot operate on a closed database."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "file_size =Path(db_file).stat().st_size\n",
    "\n",
    "print(\"The file size WAS:\", file_size/1048576,\"MB\")\n",
    "\n",
    "conn.execute(\"VACUUM\") ### SHRINK!!!!\n",
    "conn.close()\n",
    "\n",
    "file_size =Path(db_file).stat().st_size\n",
    "\n",
    "print(\"The file size is:\", file_size/1048576,\"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6658934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
